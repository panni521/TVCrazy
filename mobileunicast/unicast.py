#!/usr/bin/env python3
"""
IPTVç›´æ’­æºå¤„ç†å·¥å…·ï¼ˆGitHub Actionsé€‚é…ç‰ˆï¼‰
åŠŸèƒ½ï¼šä»æŒ‡å®šURLä¸‹è½½ç›´æ’­æºï¼Œåˆå¹¶å»é‡ã€æµ‹é€Ÿã€åˆ†ç»„å¹¶ç”Ÿæˆæ ‡å‡†M3Uæ–‡ä»¶
"""

import os
import re
import sys
import time
import socket
import argparse
import requests
from concurrent.futures import ThreadPoolExecutor, as_completed
from typing import Dict, List, Tuple
from dataclasses import dataclass
from pathlib import Path


@dataclass
class ChannelInfo:
    """é¢‘é“ä¿¡æ¯æ•°æ®ç±»"""
    name: str
    url: str
    speed: float = 0.0  # å•ä½ï¼šMB/s


class ChannelGroup:
    """é¢‘é“åˆ†ç»„å¸¸é‡ç±»"""
    CCTV = "å¤®è§†é¢‘é“"
    WEI_SHI = "å«è§†é¢‘é“"
    LOCAL = "çœçº§é¢‘é“"
    HKMOTW = "æ¸¯æ¾³å°é¢‘é“"
    CITY = "å¸‚çº§é¢‘é“"
    OTHER = "å…¶å®ƒé¢‘é“"


class IPTVProcessor:
    """IPTVç›´æ’­æºå¤„ç†å™¨"""
    
    # æ•°æ®æºURLåˆ—è¡¨ï¼ˆä»…ä¿ç•™ç¨³å®šå¯ç”¨æºï¼‰
    SOURCE_URLS = [
        "https://live.zbds.org/tv/yd.txt",
        "https://raw.githubusercontent.com/xisohi/CHINA-IPTV/main/Unicast/anhui/mobile.txt",
        "https://raw.githubusercontent.com/xisohi/CHINA-IPTV/main/Unicast/zhejiang/mobile.txt",
        "https://mycode.zhoujie218.top/me/jsyd.txt",
        "https://live.zbds.org/tv/zjyd.txt"
    ]
    
    # åˆ†ç»„åŒ¹é…å…³é”®å­—
    _group_patterns = {
        ChannelGroup.CCTV: re.compile(r'^CCTV|å¤®è§†|ä¸­å¤®'),
        ChannelGroup.WEI_SHI: re.compile(r'å«è§†$'),
        ChannelGroup.HKMOTW: re.compile(r'é¦™æ¸¯|å°æ¹¾|æ¾³é—¨|TVB|å‡¤å‡°|ç¿¡ç¿ '),
        ChannelGroup.LOCAL: re.compile(r'åŒ—äº¬|ä¸Šæµ·|å¹¿ä¸œ|æ±Ÿè‹|æµ™æ±Ÿ|å±±ä¸œ|æ²³å—|æ²³åŒ—|å››å·|æ¹–å—|æ¹–åŒ—|ç¦å»º|å®‰å¾½|æ±Ÿè¥¿|å±±è¥¿|é™•è¥¿|ç”˜è‚ƒ|é’æµ·|è¾½å®|å‰æ—|é»‘é¾™æ±Ÿ|å†…è’™å¤|å®å¤|æ–°ç–†|è¥¿è—|äº‘å—|è´µå·|å¹¿è¥¿|æµ·å—'),
        ChannelGroup.CITY: re.compile(r'çŸ³å®¶åº„|å”å±±|å¹¿å·|æ·±åœ³|æ­å·|å—äº¬|æˆéƒ½|æ­¦æ±‰|é‡åº†|è¥¿å®‰|æ²ˆé˜³|å“ˆå°”æ»¨|æµå—|é’å²›|å¤§è¿|è‹å·|æ— é”¡|å¦é—¨')
    }

    def __init__(self, top_count=10):
        self.top_count = top_count
        self.work_dir = Path(os.getenv('GITHUB_WORKSPACE', '.'))  # é€‚é…GitHub Actionsç¯å¢ƒ
        self.output_dir = self.work_dir / "dist"
        self.output_dir.mkdir(exist_ok=True)

    def _download_source(self, url: str) -> str:
        """ä¸‹è½½å•ä¸ªæºæ–‡ä»¶å†…å®¹"""
        try:
            headers = {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
            }
            response = requests.get(url, timeout=15, headers=headers)
            response.raise_for_status()
            return response.text
        except Exception as e:
            print(f"âš ï¸ ä¸‹è½½å¤±è´¥ {url}: {str(e)}")
            return ""

    def download_all_sources(self) -> List[str]:
        """å¹¶å‘ä¸‹è½½æ‰€æœ‰æºæ–‡ä»¶å†…å®¹"""
        print("ğŸ“¥ å¼€å§‹ä¸‹è½½ç›´æ’­æº...")
        contents = []
        
        with ThreadPoolExecutor(max_workers=5) as executor:
            futures = {executor.submit(self._download_source, url): url for url in self.SOURCE_URLS}
            
            for future in as_completed(futures):
                url = futures[future]
                try:
                    content = future.result()
                    if content:
                        contents.append(content)
                        print(f"âœ… æˆåŠŸä¸‹è½½: {url.split('/')[-1]}")
                except Exception as e:
                    print(f"âŒ å¤„ç†å¤±è´¥ {url}: {str(e)}")
        
        print(f"ğŸ“Š ä¸‹è½½å®Œæˆï¼Œå…±è·å– {len(contents)} ä¸ªæœ‰æ•ˆæºæ–‡ä»¶")
        return contents

    def parse_channels(self, contents: List[str]) -> Dict[str, List[ChannelInfo]]:
        """è§£ææºæ–‡ä»¶å†…å®¹ä¸ºé¢‘é“å­—å…¸"""
        print("ğŸ” å¼€å§‹è§£æé¢‘é“...")
        channel_dict: Dict[str, List[ChannelInfo]] = {}
        
        for content in contents:
            lines = [line.strip() for line in content.splitlines() if line.strip()]
            for line in lines:
                # æ”¯æŒä¸¤ç§æ ¼å¼ï¼š"é¢‘é“å,url" æˆ– "url,é¢‘é“å"
                if ',' in line:
                    parts = line.split(',', 1)
                    if len(parts) == 2:
                        name, url = (parts[0], parts[1]) if parts[0].strip() else (parts[1], parts[0])
                        name = name.strip()
                        url = url.strip()
                        if name and url and (url.startswith('http') or url.startswith('rtsp')):
                            if name not in channel_dict:
                                channel_dict[name] = []
                            channel_dict[name].append(ChannelInfo(name=name, url=url))
        
        print(f"ğŸ“‹ è§£æå®Œæˆï¼Œå…±å‘ç° {len(channel_dict)} ä¸ªç‹¬ç‰¹é¢‘é“")
        return channel_dict

    def _test_speed(self, channel: ChannelInfo) -> ChannelInfo:
        """æµ‹è¯•å•ä¸ªé¢‘é“çš„é€Ÿåº¦"""
        try:
            start_time = time.time()
            timeout = 8  # è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰
            test_size = 2 * 1024 * 1024  # æµ‹è¯•ä¸‹è½½2MB
            
            # å¯¹äºM3U8ï¼Œæ‰¾ç¬¬ä¸€ä¸ªTSåˆ†ç‰‡
            if '.m3u8' in channel.url:
                resp = requests.get(channel.url, timeout=5)
                if resp.status_code == 200:
                    for line in resp.text.splitlines():
                        if line and not line.startswith('#'):
                            ts_url = line if line.startswith('http') else f"{channel.url.rsplit('/', 1)[0]}/{line}"
                            channel.url = ts_url
                            break
            
            # æµ‹é€Ÿä¸‹è½½
            with requests.get(channel.url, stream=True, timeout=timeout) as r:
                r.raise_for_status()
                downloaded = 0
                for chunk in r.iter_content(chunk_size=1024*1024):
                    if chunk:
                        downloaded += len(chunk)
                        if downloaded >= test_size:
                            break
                        if time.time() - start_time > timeout:
                            break
            
            duration = time.time() - start_time
            if duration > 0 and downloaded > 0:
                channel.speed = (downloaded / (1024 * 1024)) / duration  # MB/s
            return channel
        except Exception:
            return channel

    def test_channel_speeds(self, channel_dict: Dict[str, List[ChannelInfo]]) -> Dict[str, List[ChannelInfo]]:
        """æ‰¹é‡æµ‹è¯•é¢‘é“é€Ÿåº¦"""
        print("âš¡ å¼€å§‹æµ‹é€Ÿ...")
        result_dict: Dict[str, List[ChannelInfo]] = {}
        
        with ThreadPoolExecutor(max_workers=3) as executor:
            futures = []
            for name, channels in channel_dict.items():
                for channel in channels:
                    futures.append(executor.submit(self._test_speed, channel))
            
            for future in as_completed(futures):
                channel = future.result()
                if channel.speed > 0:  # åªä¿ç•™æœ‰æ•ˆé€Ÿåº¦çš„é¢‘é“
                    if channel.name not in result_dict:
                        result_dict[channel.name] = []
                    result_dict[channel.name].append(channel)
        
        # æŒ‰é€Ÿåº¦æ’åºå¹¶ä¿ç•™å‰Nä¸ª
        for name in result_dict:
            result_dict[name].sort(key=lambda x: x.speed, reverse=True)
            result_dict[name] = result_dict[name][:self.top_count]
        
        print(f"ğŸ æµ‹é€Ÿå®Œæˆï¼Œæœ‰æ•ˆé¢‘é“: {len(result_dict)}")
        return result_dict

    def classify_channel(self, name: str) -> str:
        """å¯¹é¢‘é“è¿›è¡Œåˆ†ç±»"""
        for group, pattern in self._group_patterns.items():
            if pattern.search(name):
                return group
        return ChannelGroup.OTHER

    def generate_m3u(self, channel_dict: Dict[str, List[ChannelInfo]]) -> None:
        """ç”Ÿæˆæ ‡å‡†M3Uæ–‡ä»¶"""
        m3u_path = self.output_dir / "iptv_live.m3u"
        group_counts: Dict[str, int] = {}
        
        with open(m3u_path, 'w', encoding='utf-8') as f:
            f.write("#EXTM3U x-tvg-url=\"https://epg.51zmt.top:8000/e.xml\"\n")  # é™„åŠ EPGä¿¡æ¯
            
            for name, channels in sorted(channel_dict.items()):
                group = self.classify_channel(name)
                group_counts[group] = group_counts.get(group, 0) + len(channels)
                
                for channel in channels:
                    f.write(f'#EXTINF:-1 group-title="{group}",{name}\n')
                    f.write(f'{channel.url}\n')
        
        print("\nğŸ“„ ç”ŸæˆM3Uæ–‡ä»¶:")
        for group, count in sorted(group_counts.items()):
            print(f"  {group}: {count}ä¸ªé¢‘é“")
        print(f"  æ€»è®¡: {sum(group_counts.values())}ä¸ªé¢‘é“æº")

    def run(self):
        """æ‰§è¡Œå®Œæ•´å¤„ç†æµç¨‹"""
        start_time = time.time()
        print("=== IPTVç›´æ’­æºå¤„ç†å·¥å…· ===")
        
        contents = self.download_all_sources()
        if not contents:
            print("âŒ æ²¡æœ‰è·å–åˆ°ä»»ä½•æºæ–‡ä»¶ï¼Œç¨‹åºé€€å‡º")
            return
        
        raw_channels = self.parse_channels(contents)
        if not raw_channels:
            print("âŒ æ²¡æœ‰è§£æåˆ°ä»»ä½•é¢‘é“ï¼Œç¨‹åºé€€å‡º")
            return
        
        valid_channels = self.test_channel_speeds(raw_channels)
        if not valid_channels:
            print("âŒ æ²¡æœ‰æœ‰æ•ˆé¢‘é“é€šè¿‡æµ‹é€Ÿï¼Œç¨‹åºé€€å‡º")
            return
        
        self.generate_m3u(valid_channels)
        
        end_time = time.time()
        print(f"\n=== å¤„ç†å®Œæˆ (è€—æ—¶: {end_time - start_time:.2f}ç§’) ===")
        print(f"è¾“å‡ºç›®å½•: {self.output_dir.absolute()}")


if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="IPTVç›´æ’­æºå¤„ç†å·¥å…·")
    parser.add_argument("--top", type=int, default=10, help="æ¯ä¸ªé¢‘é“ä¿ç•™çš„æœ€å¤§æºæ•°é‡")
    args = parser.parse_args()
    
    processor = IPTVProcessor(top_count=args.top)
    processor.run()
